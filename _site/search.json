[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Yo whats up it’s me Porter!! (That’s my cousin Josh)"
  },
  {
    "objectID": "articles/coding/cpp_vs_python.html",
    "href": "articles/coding/cpp_vs_python.html",
    "title": "C++ vs Python For Machine Learning",
    "section": "",
    "text": "Both C++ and Python are powerful, capable languages. Lets explore some of their pros and cons for machine learning."
  },
  {
    "objectID": "articles/coding/cpp_vs_python.html#background",
    "href": "articles/coding/cpp_vs_python.html#background",
    "title": "C++ vs Python For Machine Learning",
    "section": "",
    "text": "Both C++ and Python are powerful, capable languages. Lets explore some of their pros and cons for machine learning."
  },
  {
    "objectID": "articles/math/nns.html",
    "href": "articles/math/nns.html",
    "title": "The Linear Algebra and Multivariable Calculus behind Artificial Neural Networks",
    "section": "",
    "text": "A neural network is a type of artifitial intelligence model that uses linear algebra and multivariable calculus to learn and store the relationship between an input vector and an output vector that minimizes the loss function. Here is the mathematics for a single layer artificial neural network.\n\nNOTE: DNN’s (Deep Neural Networks) or neural networks with more than 1 hidden layer will be covered in another article.\n\n\n\n\nTransformations, mappings, vector and matrix multiplication and other operations from linear algebra\nPartial derivatives and their implications from multivariable calculus"
  },
  {
    "objectID": "articles/math/nns.html#prerequisites",
    "href": "articles/math/nns.html#prerequisites",
    "title": "The Linear Algebra and Multivariable Calculus behind Artificial Neural Networks",
    "section": "",
    "text": "Transformations, mappings, vector and matrix multiplication and other operations from linear algebra\nPartial derivatives and their implications from multivariable calculus"
  },
  {
    "objectID": "articles/math/nns.html#summary",
    "href": "articles/math/nns.html#summary",
    "title": "The Linear Algebra and Multivariable Calculus behind Artificial Neural Networks",
    "section": "Summary",
    "text": "Summary\nTo summarise the forward propogations process…\n\\[\nT_1(\\vec{x}) = \\sigma(W_1\\vec{x}) = \\vec{h}\n\\newline\nT_2(\\vec{h}) = W_2\\vec{h} = \\vec{y}\n\\]\nAre the linear mappings represented by weight matrices that map the input vector to the hidden vector to the output vector. Now we will study the process of optimizing the weights to minimize the loss function \\(\\mathcal{L}\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Stretch",
    "section": "",
    "text": "Cool data science blog. Currently in its early stages please be patient."
  }
]